---
layout: post
title: "操作系统笔记"
date: 2018-02-20
comments: true
tags: 
  - 学习笔记
  - OS
---



### 概述

操作系统学习笔记，包括：

1. 操作系统基本概念
2. 进程、线程
3. 处理器调度
4. 同步机制
5. 存储模型
6. 文件系统
7. IO
8. 死锁

<!-- more -->

重点：

《现代操作系统》(第三版)

* 教材：
  * 第一章： 1.1 、1.2 、 1.4
  * 第10章： 10.2.5 linux
  * 第11章： 11.3.1 
* 重点概念：
  * 操作系统定义
  * 操作系统三个作用
  * 操作系统四个特点
  * SPOOLING技术
  * windows、linux、unix架构及主要功能

#### 操作系统的定义与作用

1. 有效管理资源

> 1. 静态分配：在进程执行前准备好需要的所有资源，会造成资源浪费
> 2. 动态分配：进程需要时进行申请

2. 通过命令接口、编程接口为用户提供服务

3. 对硬件机器的扩展

   > 对硬件进行抽象，硬件之上的虚拟机器

#### 操作系统的特征

1. 并发 concurrency: 指处理多个同时性活动的能力

   > 引发问题： 活动切换、保护、相互依赖的活动的同步
   >
   > 并行parallel： 不同程序同时在多个硬件上执行

2. 共享 sharing：操作系统与用户的程序共享系统中的资源

   > 操作系统要对资源进行合理分配和使用
   >
   > 1. 互斥共享（打印机）
   > 2. 同时共享（代码、文件）

3. 虚拟 virtual：物理实体映射为若干个对应的逻辑实体（分时、分空间）

   > 目的：提高资源利用率
   >
   > CPU：每个进程 “虚处理器”
   >
   > 存储器：虚拟地址空间
   >
   > 显示器：多窗口

4. 随机：随时对不可预测的次序发生的事件进行响应并处理

   > * 进程运行速度不可预知
   > * 难以重现系统在某个时刻的状态

#### 操作系统的架构

Windows 、 Unix 、 Linux

#### 操作系统的分类

发展： 硬件发展、应用需求发展、软件技术发展

目的：充分利用硬件，提供更好服务

掌握各种操作系统的目标和不同点

* 批处理操作系统

  1. 方式

     > 系统操作员从用户处收集作业并输入系统，而后启动操作系统，操作系统自动处理作业并输出，系统操作员从输出处获取作业

  2. 目的： 提高资源利用率，增加吞吐量

  3. 概念：

     * 作业：程序、数据、作业说明素
     * 成批：由若干作业组成
     * 批作业处理：对每个作业做相同处理

  4. 问题：

     * 输入输出慢，由主机完成，CPU处于等待状态
     * 解决：用卫星机：完成输入输出，暂存输入输出结果，流程：用户->卫星机->系统操作员->计算机->系统操作员->卫星机->用户

  5. 分类：

     * 单道批处理：一次处理一个作业
     * 多道批处理：一次选中多个作业进行处理

  6. 技术： Spooling 同时外围设备联机操作，假脱机技术

     > 用磁盘作缓冲，输入输出和计算并行在一台机器上进行
     >
     > 现代打印过程通常用spooling技术

* 分时系统：time-sharing ，最早的交互式系统

  1. 方式：

     * 一台主机对多个终端，用户在终端输入命令等待结果

  2. 概念：时间片 （time slice）

     操作系统将CPU时间划分成若干片段，以时间片为单位轮流为终端服务，每次一个时间片

  3. 特点：利用人的错觉，使得人感觉系统只在为自己服务（每个用户在一个虚拟机上运行）

  4. 目标：及时响应

通用操作系统：分时和批处理结合，原则：以分时优先，批处理在后

* 实时操作系统
  1. 概念：计算机能及时响应外部事件的请求，在严格时间内完成处理
  2. 分类：
     1. 实施过程控制（军事控制、航空）
     2. 实时通信处理（订票）
  3. 目标：
     * 严格时间范围内响应
     * 高可靠性
  4. 特征：
     1. 硬实时系统：某个动作必须在规定时间内或规定时刻完成（焊接）
     2. 软实时系统：接受偶尔违反时限（播放音乐、视频等）
* PC操作系统
  1. 目标：
     * 界面友好、使用方便
     * 丰富的应用软件
* 网络操作系统
  1. 概念：按网络体系结构协议标准开发的软件
  2. 功能：网络管理，通信，安全，资源共享和网络应用
  3. 追求目标：相互通信，资源共享
* 分布式操作系统
  1. 概念：以计算机网络或多处理器为基础，特征是处理分布在不同计算机上
* 嵌入式操作系统
  1. 概念：
     * 在各种设备、装置中完成特定功能的软硬件系统（汽车、手机、播放器等）
     * 大设备、装置中的一部分
     * 对反应时间、处理时间有严格要求

### 操作系统运行环境

重点：

* 理解计算机系统的保护机制
  * 掌握处理器状态
  * 掌握特权指令与非特权指令
* 掌握中断、异常机制
  * 掌握中断、异常的基本概念
  * 理解中断、异常机制的工作原理
* 掌握系统调用机制
  * 掌握系统调用的设计原理
  * 掌握系统调用的执行过程

重点阅读：

* 第一章： 1.3、 1.6
* 第二章： P52 图2-5

重点概念：

​	CPU状态、内核态 用户态、特权指令 非特权指令、中断、异常、中断响应、中断向量、中断处理程序、系统调用、陷入指令、系统调用号、系统调用表

#### 处理器状态

中断与异常机制

CPU由运算器、控制器、寄存器及高速缓存组成

* 两类寄存器：
  * 用户可见寄存器：高级语言编译器通过优化算法分配寄存器并使用，减少访问内存次数
  * 控制和状态寄存器：用于控制处理器操作，只能由操作系统代码使用，
    * 程序计数器 PC
    * 指令寄存器 IR
    * 程序字寄存器 PSW

并发和共享 -> 要求保护： 用户程序不对操作系统干扰

要求硬件提供基本运行机制：

* CPU具有特权级别，不同特权级下运行不同指令集合
* 将OS与用户程序隔离

cpu状态通常为两种、三种或四种：

​	在程序状态字寄存器PSW专门设置一位，根据程序的使用权限设置不同的CPU状态

操作系统需要两种CPU状态：

       	1. 内核态 ： 运行操作系统程序
     	2. 用户态： 运行用户程序

指令分类：

1. 特权指令：只能由操作系统使用，用户程序不能使用（启动IO、内存清零）
2. 非特权指令：操作系统和用户程序都可以使用（控制转移）

CPU状态的转换：

* 用户态 -> 内核态： 唯一途径：中断、异常、陷入机制（提供给用户程序的接口，用于调用操作系统功能）
* 内核态 -> 用户态：设置程序状态字PSW

#### 中断与异常机制

操作系统是由 中断驱动的 或是 事件驱动的

概念：CPU对系统发生的某个事件的反应

事件的发生改变了CPU的控制流

主要作用：

* 及时处理外部设备中断请求
* 捕获用户程序提出的服务请求
* 防止用户程序执行过程中的破坏活动

特点：

* 随机发生
* 自动处理 (硬件自动完成的)
* 可恢复

中断的引入原因：支持CPU与设备之间的并行操作

异常的引入原因：CPU执行指令时本身出错

事件：

* 中断（外中断）：
  * IO中断（按键、外部设备）
  * 时钟中断（定时器，CPU时间片到了）
  * 硬件故障（充电）
* 异常（内中断）：
  * 系统调用
  * 页故障、页错误（缺页）
  * 保护性异常（只读文件和写操作）
  * 断点指令（debug）
  * 其他程序性异常（算术溢出）

异常类别：

* 陷入 Trap ： 有意识安排的      同步   返回到下一条指令
* 故障 Fault： 可恢复的错误     同步    返回到当前指令
* 终止 Abort： 不可恢复的错误   同步   不会返回

#### 中断、异常机制的工作原理

**硬件和软件相互配合**

硬件：响应异常

​	捕获请求，以一定方式相应，把CPU的控制权交给处理程序

软件：处理异常

​	识别类型并完成处理

中断响应：硬件

​	每条指令执行最后扫描中断寄存器查看是否有中断信号，若有，则中断硬件将中断触发器内容按编码送入PSW，并查询中断向量表引出处理程序

​	中断向量：一个内存单元，存放中断处理程序入口地址和程序运行时需要的处理机状态字

​	流程： 设备发出中断信号 -> 硬件保存现场(PSW,PC) -> 根据中断码查表 -> 中断处理程序入口地址送入相应寄存器 -> 执行处理程序	

中断处理：软件

* 保存相关寄存器信息（硬件只保存关键寄存器）
* 分析具体原因
* 执行处理功能
* 恢复现场，返回被打断的程序

#### 系统调用机制

操作系统给用户提供的接口，在编程时可调用的操作系统功能

使CPU状态从用户态陷入内核态

区分： 系统调用、库函数、API、内核函数

​	应用程序通常借函数库、API接口间接进行系统调用

​	内核函数包含系统调用，大部分不开放给用户

设计系统调用机制：

       	1. 利用中断异常机制
     	2. 选择一条特殊指令：陷入指令，从用户态切换到内核态
     	3. 每个系统调用给定一个编号
     	4. 存放系统调用服务例程的入口地址

用户的参数传递给内核：（从用户栈到内核栈）

1. 陷入指令自带参数（长度有限）
2. 通用寄存器传递参数（寄存器个数有限） （主要方法）
3. 内存中开辟专用堆栈区传递参数

系统调用执行过程：

1. 中断异常机制：硬件保护现场，查询中断向量表，控制权交给系统调用总入口程序
2. 系统调用总入口程序：保存现场，把参数保存到内核栈，查系统调用表把控制权转给相应的系统调用例程或内核函数
3. 执行系统调用例程
4. 恢复现场，返回用户程序


### 进程、线程模型

重点：

​	第2章： 2.1、 2.2(除 2.2.8 - 2.2.10外)

重点概念：
​	进程、进程状态及切换、进程控制、PCB、进程地址空间、进程上下文环境、线程、线程属性、用户级线程、核心级线程、Pthreads、可再入程序、原语、web服务器

#### 进程的基本概念

多道程序设计： 允许多个程序同时进入内存并运行

并发环境：一段时间间隔内，单处理器由两个或以上程序同时处于开始运行但尚未结束的状态且次序不是事先确定的

进程 process： 具有独立功能的程序关于某个数据集合上的一次运行活动，是资源分配和调度的单位，又称任务

  * 程序一次执行过程
  * 正在运行程序的抽象
  * 一个CPU变换成多个虚拟的CPU
  * 系统资源以进程为单位分配，如内存、文件
  * 每个进程有独立的地址空间
  * 操作系统把CPU调度给需要的进程

进程控制块 PCB

* 又称 进程描述符、进程属性
* 操作系统用于管理控制进程的一个专门数据结构
* 记录进程的各种属性，并描述进程的动态变化过程
* 是系统感知进程的唯一标识，与进程一一对应
* 包含：
  * 进程描述信息
    * 进程标识符 ID，唯一
    * 进程名，不唯一
    * 用户ID
    * 进程组关系（子进程、父进程等）
  * 进程控制信息
    * 当前状态、优先级、代码执行入口地址、磁盘地址、队列指针等
  * 所拥有资源和使用情况
    * 虚拟空间空间状况
    * 打开文件列表
  * CPU现场信息
    * 寄存器值
    * 指向该进程页表的指针

进程表： 所有进程的PCB的集合（大小固定）

#### 进程状态及状态转换

进程三种基本状态：运行态、就绪态、等待态

运行态 running：

​	占有CPU并在CPU上运行

就绪态 ready：

​	已具备运行条件，但没有空闲CPU

等待态、阻塞态、封锁态、睡眠态：

​	因等待某一事件而暂停（如读盘）

状态转换：

1. 就绪 -> 运行：调度程序选中
2. 运行 -> 就绪：运行进程用完时间片，或高优先级进程进入就绪态
3. 运行 -> 等待：进程等待事件（请求OS服务，资源尚未访问，等待IO，等待另一进程等） 
4. 等待 -> 就绪：所等待的事件发生

其它状态：

*  创建态 new：已完成创建进程必备工作（PID、PCB），但未被同意执行（资源有限）
*  终止态 terminated：执行后，完成数据统计工作，回收资源
*  挂起态 suspend：进行负载调节，进程不占用内存空间，进程映像交换到磁盘

![](http://ot1c7ttzm.bkt.clouddn.com/sevenlevel.png)

进程队列：

* 每一类进程建立一个或多个队列
* 队列元素为PCB
* 进程状态改变，其PCB从一个队列进入另一队列

#### 进程控制

完成进程状态之间的转换，由具有特定功能的原语完成

原语 primitive：完成某特定功能的程序，不可分割、不可中断

1. 进程创建
   1. 新进程分配唯一标识ID以及进程控制块PCB
   2. 分配地址空间
   3. 初始化PCB：设置默认值
   4. 设置相应的队列指针
2. 进程的撤销：结束进程
   1. 回收进程占用的资源（关闭文件、断开网络、回收内存）
   2. 收回PCB
3. 进程阻塞：由**进程自己**执行阻塞原语，使自己由运行态变为阻塞态

UNIX下进程控制： 系统调用

* fork 通过复制调用进程建立新进程
* exec 用新代码覆盖原来的地址空间，建立新进程
* wait 进程进入阻塞态 
* exit 终止进程运行 

#### 进程相关概念

进程的分类：

1.  
   * 系统进程：优先级较高
   * 用户进程
2.  
   * 前台进程
   * 后台进程
3.  
   * CPU密集型进程
   * IO密集型进程

进程的层次结构：

* Unix进程家族树：init为根
* Windows：地位相同

进程和程序的区别：

* 进程更准确刻画并发
* 程序是静态的，进程是动态的
* 进程由生命周期，程序相对长久
* 一个程序可以对应多个进程
* 进程可以创建其它进程，程序不行

进程映像 image： 进程执行活动全过程的静态描述，程序+数据+栈（用户栈+内核栈）+PCB

上下文context 切换： CPU硬件状态从一个进程切换到另一个进程的过程

> 进程运行时硬件状态保存在CPU的寄存器，当进程不运行时，寄存器的值要保存到PCB中

#### 线程的引入

引入原因：

* 应用需要 （打字与排版与存盘、web服务器）
* 开销考虑
  * 线程开销小
    * 创建新线程花费时间少
    * 线程切换花费时间少
    * 线程通信无需调用内核，直接共享资源
* 性能考虑：多处理器处理多线程

线程的基本概念

线程集成了CPU调度单位

进程还是资源拥有者

线程 thread：进程中的一个运行实体，是CPU的调度单位，也称轻量级进程

属性：

* 有标识符ID
* 有状态及状态切换
* 不运行时需要保存上下文
* 有自己的栈和栈指针
* 共享所在进程的地址空间和其他资源
* 可以创建、撤销另一个线程，程序一开始是单线程执行

#### 线程机制的实现

* 用户级线程 （unix）
  * 在用户空间建立线程库
  * 通过 运行时系统（run-time system）完成管理工作
  * 内核管理、进程都不知道线程的存在
  * 线程切换不需要内核态特权，不需要操作系统干预
  * 优点：
    * 线程切换快
    * 调度算法是应用程序特定的
    * 可运行在任何操作系统上
  * 缺点：
    * 内核只分配处理器给进程，同一进程两线程不能同时运行于两个处理器
    * 系统调用大多是阻塞的，内核阻塞进程时所有线程也被阻塞
* 核心级线程 （windows）
  * 内核管理所有线程，向应用程序提供API
  * 内核维护线程和进程
  * 线程切换需要内核
  * 以线程为单位进行调度
* 混合模型：
  * 线程在用户空间创建
  * 线程调度在核心态完成

### 处理器调度

教材重点：

* 第二章： 2.4
* 第11章： 11.4.3

重点：

* 掌握处理器调度的相关概念：
  * 调度时机、进程切换
  * 调度标准：吞吐量、周转时间、响应时间
  * 优先级/优先数、 抢占/非抢占、 IO型与CPU型
* 掌握主要的调度算法：
  * 先来先服务、短作业有限、最高响应比优先
  * 时间片轮转、最高优先级
  * 多级反馈队列
* 了解Windows、多处理器调度的基本思想

#### 处理器调度的相关概念

CPU调度：控制、协调进程对CPU的竞争，按一定调度算法从就绪队列中选一个进程把CPU使用权交给被选中进程

若没有就绪进程，系统会安排系统空闲进程或idle进程

三个问题：

* 按什么原则选择下一个进程：调度算法
* 何时选择：调度时机
* 如何让被选中进程上CPU运行：调度过程（进程上下文切换）

调度时机： 内核对中断、异常、系统调用处理后返回用户态时

 * 进程正常终止或因错误终止
 * 新进程创建、等待进程变成就绪
 * 进程从运行态进入阻塞态
 * 进程从运行态进入就绪态

调度过程：

* 进程切换：一个进程让出CPU，另一个进程使用CPU
  * 包括对原进程状态的保存，和对新进程状态的恢复
  * 过程
    * 切换全局页目录以加载新的地址空间
    * 切换内核栈和硬件上下文
  * 开销：
    * 直接开销：内核完成切换所用的CPU时间
      * 保存、恢复寄存器
      * 切换地址空间
    * 间接开销
      * 高速缓存、缓冲区缓存、TLB失效

调度算法的设计：

* 衡量指标：
  * 吞吐量 throughput： 单位时间完成的进程数目
  * 周转时间 TT turnaround time：进程从提出请求到运行完成的时间
  * 响应时间 RT response time：提出请求到第一次回应的事件
  * CPU利用率：CPU有效工作的时间
  * 等待时间：进程在就绪队列中等待的时间

![调度算法设计](http://ot1c7ttzm.bkt.clouddn.com/schedulalgo.png)

#### 调度算法的设计

优先级：

 * 优先级与优先数
 * 静态与动态

占用CPU的方式：

* 抢占式 preemptive：
  * 有优先级更高的进程就绪时，系统可强行剥夺正在运行进程的CPU
* 不可抢占式 non-preemptive：
  * 除非因自身原因不能运行，否则进程会一直运行下去

进程按执行过程行为划分：

* IO密集型 IO-bound
* CPU密集型 CPU-bound

时间片： time slice 或 quantum：

 * 分配给调度上CPU的进程的时间段

#### 批处理中的调度算法

* 先来先服务 FCFS  first come first serve：
  * 按进程就绪先后顺序使用CPU
  * 非抢占式
  * 优点： 公平、实现简单
  * 缺点：短进程需要等长时间
* 最短作业优先 SJF shortest job first：
  * 最短完成时间的进程优先
  * 非抢占式
  * 改善短作业的周转时间
  * 优点：最短平均周转时间（所有进程同时可运行时）
  * 缺点：不公平，长任务饥饿现象 starvation
* 最短剩余时间优先 SRTN  shortest remaining time next：
  * 最短作业优先的抢占版本
* 最高响应比优先 HRRN  highest response ratio next
  * 调度时，先计算每个进程的响应比R，总选择R最高的进程
  * R = $\frac{周转时间}{处理时间}$ =  $1+\frac{等待时间}{处理时间}$ 

#### 交互式系统采用的调度算法

* 轮转调度 RR round robin
  * 目标：为短任务改善平均响应时间
  * 思路：
    * 周期性切换
    * 每个进程一个时间片
    * 时钟中断 -> 轮换
  * 时间片选择：
    * 太长：短进程响应时间长
    * 太短：切换开销大
  * 优点：公平、利于交互式计算
  * 缺点：进程切换使得轮转开销大、对大小相近的进程不利、对IO型进程不利
* 最高优先级调度 HPF highest priority first：
  * 通常： 系统进程优先于用户进程、前台进程优先于后台，偏向于IO型进程
  * 优先级反转问题 priority inversion（基于优先级的抢占式时）：低优先级进程占有高优先级进程需要的资源
    * 影响： 
      * 系统错误
      * 高优先级进程停滞不前
    * 解决方案：
      * 设置优先级上限（临界区的进程优先级最高）
      * 优先级继承（低优先级继承高优先级）
      * 使用中断禁止（临界区进程不响应中断）
* 多级反馈队列 Multiple feedback queue：
  * 设置多个就绪队列，第一级队列优先级最高
  * 时间片长度不同，级别越低，时间片越大
  * 每个队列用时间片轮转方式调度
  * 新进程创建就绪后，进入第一级
  * 进程用完时间片并放弃CPU，进入下一级就绪队列
  * 因阻塞放弃CPU的进程从等待队列出来时回到原来就绪队列
* 最短进程优先 Shortest process next

![调度算法总结](http://ot1c7ttzm.bkt.clouddn.com/schedulalgo1.png)

多处理器调度算法设计：

* 不仅选择哪个进程，还要选择在哪个CPU
* 考虑进程在多个CPU迁移的开销
* 负载均衡问题

#### Windows 线程调度

调度单位是线程

采用基于动态优先级、抢占式调度，结合时间配额的调整

引发线程调度的条件：

* 线程优先级改变
* 线程改变了亲和affinity处理机集合
* 正常调度条件（4条）

32个优先级，分三类：

* 实时优先级：不改变优先级
* 可变优先级：在一定范围内可变
* 系统线程

时间配额：配额单位的整数，不是时间长度值

调度策略：

* 主动切换
* 抢占： 
  * 被抢占线程：
    * 实时优先级：时间配额重置
    * 可变优先级：时间配额不变
* 时间配额用完
  * A优先级未降低：A进入原就绪队列末尾
  * A优先级降低

### 同步机制

重点：

* 基本概念：
  * 竞争条件、临界区
  * 进程同步、互斥
  * 自旋锁（忙等待）
* 信号量，PV操作
* 经典问题模型及解决方案
  * 生产者消费者问题，读者写者问题

教材：

* 第2章： 2.3.1~2.3.5， 2.5.2

#### 进程互斥

竞争条件 race condition： 两个或多个进程读写某些共享数据，最后结果取决于进程的精确时序

进程互斥 mutual exclusive：共享资源需要排他性使用，各进程之间竞争使用这些资源

临界资源、共享资源、互斥资源 critical resource： 某些资源一次只允许一个进程使用

临界区（互斥区）：critical section：各个进程中对临界资源实时操作的程序片断

临界区的使用原则：

* 没有进程在临界区时，想进入的可以进入
* 不允许两个进程同时处于临界区
* 临界区外的进程不得阻塞其他进程进入临界区
* 不得使进程在临界区外无限等待

解决方案：

* 软件：
  * dekker解法
  * peterson解法
* 硬件：
  * 屏蔽中断
  * TSL（XCHG）指令

忙等待 busy waiting：进程得到临界区访问权之前，持续测试

* 自旋锁 spin lock （多处理器）
* 为什么不直接切换进程： 临界区使用时间一般很短，切换进程的开销更大

优先级反转（倒置）：由于临界区保护带来的问题

#### 软件解法

解法1：

* 用free作为标志：临界区是否空闲
  * true：有进程在临界区
  * false：无进程在临界区
  * 初始值：false
* 使用 lock(),unlock()作为原语

dekker算法：

* 引入turn变量，判断是否轮到自己

peterson算法：

* 解决了互斥访问的问题，而且克服了强制轮流的缺点
* 通过 enter_region()  和 leave_region()函数
* while( turn==process && interested[other]==TURE );

#### 硬件解法

通过指令完成

解法1：中断屏蔽方法

* 使用  开关中断 指令 （特权指令）
* 入临界区： 执行 关中断 指令
* 出临界区： 执行 开中断 指令
* 优点：简单高效
* 缺点：
  * 代价高，限制CPU并发能力
  * 不适用于多处理器
  * 适合操作系统，不适合用户进程

解法2：测试并加锁 指令：

* TSL指令：TEST AND SET LOCK
* 复制 锁 到寄存器 并把锁置为1（上锁）
* 判断寄存器是不是0
  * 若不是0，跳转到enter_region（反复循环）
  * 若是0，返回，进入临界区

解法3： 交换 指令：

* XCHG指令：EXCHANGE
* 寄存器设置为1，交换寄存器和锁的内容，判断寄存器是否是0（与TSL类似）

#### 进程同步

进程同步 synchronization：多个进程中发生的事件存在某种时序关系，需要合作

生产者、消费者问题（有界缓冲区）：

* 一个或多个生产者生产某种数据放在缓冲区
* 有消费者从缓冲区中取数据，每次取一项
* 只能有一个生产者或一个消费者对缓冲区进行操作
* 问题：
  * 缓冲区满时，生产者不添加数据
  * 缓冲区空时，消费者不移走数据
* 避免忙等待
  * 睡眠 与 唤醒 操作（原语）


#### 信号量及P、V操作

典型的进程同步机制

信号量：特殊的变量，用于进程间传递信息的整数值 （count、queue）

可执行的操作： 初始化、 P（test） 、 V（increment）

P操作： 测试

* 把信号量的值减一
* 判断信号量是否 < 0 ：
  * <0：该进程状态为阻塞态，插入等待队列 s.queue末尾，重新调度
  * false：执行进程

V操作：

* 信号量的值+1
* 判断信号量是否<=0:
  * true ：唤醒s.queue的一个进程，插入就绪队列

P、 V操作是原语操作 primitive or atomic action

最初提出：二元信号量（解决互斥）

推广：一般信号量（解决同步）

用PV解决互斥问题：

* 分析并发进程关键活动，划定临界区
* 设置信号量 mutex，初始值为1
* 临界区前实施 P
* 临界区后实施 V

用PV解决生产者消费者问题：

* 用full、empty两个变量记录满缓冲区和空缓冲区数目
* 分别用P、V操作维护full和empty
* 用 mutex 维护互斥，防止同时读写buffer![PV](http://ot1c7ttzm.bkt.clouddn.com/PV.png)
* 两边的P操作顺序不可逆，必须先判断empty或full才能判断mutex（因为P操作可能使进程进入阻塞态）
* 两边的V操作顺序可逆
* 位置：尽可能缩小临界区

PV操作解决读者、写者问题：

* 多个进程共享一个数据区，分为两组：

  * 读者进程：只读数据区数据
  * 写者进程：只写数据区数据

* 条件：

  * 允许多个读者同时读
  * 不允许多个写者同时操作
  * 不允许读写同时
  * （读写互斥，写者之间互斥）

* Linux提供的读写锁：

* 第一类读者写者问题：读者优先：

  * 若有写者在等，有其他读者在读，则新读者可以读
  * 有读者在读，写者等待
  * 解法：
    * 第一个读者做P操作，最后一个读者做V操作

  ​


### 同步机制（2）

重点：

* 管程：
  * 如何保证互斥
  * 如何保证同步：条件变量及wait、signal
  * HOARE管程
  * MESA管程
* 进程间通信：
  * 消息传递、共享内存、管道
* Pthread中的同步机制
* Linux的IPC机制

教材：

* 第二章： 2.3.6～ 2.3.9

#### 管程 monitor

出现原因： 信息量机制不足：程序编写困难、易出错（PV操作的位置）

解决：在程序设计语言中引入管程成分：高级同步机制

定义：

* 一个特殊的模块
* 每个管程有一个名字
* 管理共享资源的数据结构及其上操作的一组过程组成

进程与管程： 进程只能通过调用管程中的过程来间接访问管程的数据结构

管程解决的问题：

* 互斥：
  * 管程是互斥进入的：为了保证管程中数据结构的数据完整性
  * 互斥性由编译器负责保证
* 同步：
  * 管程中设置条件变量及等待、唤醒操作以解决同步问题
  * 可以使一个进程或线程在条件变量上等待或唤醒

使用管程的问题：

* 进入管程的操作执行唤醒操作（P唤醒Q）：
  * 规定唤醒操作为管程中最后一个可执行的操作
  * P等待，Q执行 （HOARE管程）
  * Q等待，P继续执行（MESA管程）

HOARE管程：

* 管程内增加紧急等待队列，P唤醒Q后P进入紧急等待队列（优先级高于入口等待队列）
* 管程外有入口等待队列
* 条件变量：在管程内部说明和使用的一种特殊类型的变量
  * wait操作：紧急队列非空，则唤醒第一个等待者，否则释放管程互斥权，执行该操作的进程进入c链末尾
  * signal：c链为空则相当于空操作，否则唤醒第一个等待者，执行该操作的进程进入紧急等待队列
* 缺点：
  * 两次额外的进程切换

管程的实现：

* 直接构造：效率高
* 间接构造：用某种已经实现的同步机制构造（如信号量及PV操作）


MESA管程：（P唤醒Q，P继续执行）

* signal -> notify： notif(x)使得x条件队列得到通知，发信号的进程继续执行
* notify的结果：条件队列头的进程在将来合适的时候恢复执行
* 不能保证在它之前没有其他进程进入管程，因此进程必须重新检查条件：用while循环取代if语句检查条件
* 导致对条件变量至少多一次额外检测，对等待进程什么时候执行没有限制
* 对notify的改进：
  1. 每个条件原语关联计时器，超过一定等待时间的进程直接进入就绪态
  2. broadcast：所有在该条件上等待的进程都被释放且进入就绪序列

HOARE和MESA的比较：

* MESA一般优于HOARE：MESA错误较少
* MESA：每个过程收到信号后重新检查管程变量，且使用while

#### PTHREAD中的同步机制

通过互斥量保护临界区： Pthread_mutex

解决同步问题：条件变量： wait \ signal \ broadcast

#### 进程间通信机制

原因：

* 信号量和管程的不足
* 不适合多处理器的情况

进程通信机制：消息传递：send & receive 原语

适用于： 分布式系统、单处理器系统、共享内存的多处理器系统

通信方式：

* 消息传递
  * 操作系统空间设置消息缓冲区：
    * 消息头（消息类型，进程ID：发送、接收，消息长度，控制信息）
    * 消息体
  * 发送原语，由操作系统完成
  * 过程：陷入内核、复制消息、消息入队（接收进程的PCB消息队列指针）、复制消息
  * 通过PV操作实现
* 共享内存
  * 需要解决两个问题：
    * 物理内存中建立共享空间，并建立两个进程的地址空间到内存的映射
    * 读者写者问题
* 管道 pipe：
  * 利用缓冲传输介质：内存或文件连接两个进程
  * 问题：
    * 字符流方式写入读出
    * 先入先出顺序
    * 管道通信必须提供协调能力：互斥、同步、判断对方进程是否存在
* 套接字
* 远程过程调用

#### 典型操作系统的IPC机制

linux的进程通信机制：

* 用户程序：管道、消息队列、共享内存、信号、套接字
* 内核同步机制：原子操作、自旋锁、读写锁、信号量、屏障

原子操作：

* 不可分割，不会被打断
* 常用于资源计数

屏障 barrier：

* 同步机制
* 用于对一组线程进行协调，要求所有线程到达一个汇合点后一起向前


### 存储模型（1）

重点：

* 地址重定位
* 基本内存管理方案
* 物理内存管理技术
* 交换技术

教材：

* 第3章 3.1、 3.2

#### 地址重定位

进程中的地址不是最终的物理地址

进程运行前无法计算出物理地址

地址重定位：

* 逻辑地址（相对地址、虚拟地址）：
  * 用户程序经过编译汇编后形成目标代码，首地址为0，其它地址相对于首地址编址
  * 不能用逻辑地址在内存中读取信息
* 物理地址（绝对地址，实地址）：
  * 内存存储单元的地址，可直接寻址
* 概念：需要将用户程序的逻辑地址转换为可由其直接寻址的物理地址
* 分类：
  * 静态重定位：
    * 用户程序加载到内存时，一次性实现逻辑地址到物理地址的转换
    * 一般由软件完成
  * 动态重定位：（常用）
    * 进程执行过程中进行地址变换：逐条指令执行时完成地址转换
    * 需要硬件部件支持（部件：内存管理单元MMU memory management unit）

#### 物理内存划分

空闲内存管理：

* 等长划分：
  * bitmap 位图：每个分配单元对应一位
* 不等长划分：
  * 空闲区表、已分配区表：表中每一项记录起始地址、长度、标志
  * 空闲块链表：每个表项用链相连

内存分配算法：

* 首次适配 first fit：空闲区表第一个满足进程要求的空闲区
* 下次适配 next fit：从上次找到的空闲区接着找
* 最佳适配 best fit：查找整个表，找到满足要求的最小空闲区
* 最差适配 worst fit：总分配满足进程要求的最大空闲区

空闲区划分：一部分供进程使用，一部分作为新的空闲区

回收问题：

* 内存回收算法：
  * 某一块归还后，空闲空间合并，修改空闲区表
  * 四种情况：
    * 上相邻、下相邻、上下都相邻、上下都不相邻

伙伴系统：

* linux底层内存管理采用
* 经典的内存分配方案
* 主要思想： 内存按2的幂划分，组成空闲块链表，查找最佳匹配
* 算法：
  * 首先将整个空间看做一块 $2^U$
  * 假设进程申请空间大小为s，若满足 $ 2^{U-1}<s<=2^U $则分配整个块
  * 否则把块划分成两个大小相等的伙伴 $2^{U-1}$
  * 一直划分直到产生大于等于s的块
* 进程使用完后归还空间，空间进行可能的合并

#### 基本内存管理方案（1）

整个进程进入内存连续区域

以进程为单位装载

方案：

* 单一连续区：
  * 特点：一段时间内只有一个进程在内存
  * 简单，但内存利用率低
* 固定分区：
  * 分区：内存空间分割
  * 分区固定不变，大小可以相同也可以不同
  * 一个分区装一个进程
* 可变分区：
  * 根据进程需要把空闲空间分割，分配进程，剩余部分成为新的空闲区
  * 缺点：有外碎片(进程之间的小空闲空间无法分配)，导致内存利用率下降
  * 碎片：很小的，不易利用的空闲区
  * 问题解决：紧缩技术 memory compaction：
    * 在内存移动程序把小空闲区合并：
    * 需要考虑：
      * 系统开销
      * 移动时机

#### 基本内存管理方案（2）

一个进程进入内存中若干不连续区域

方案：

* 页式存储管理：
  * 用户进程被划分为大小相等的部分称 页 page 或页面
  * 内存空间按同样大小分区域，称页框 page frame
  * 内存分配：
    * 以页为单位分配，按进程需要的页数分配
    * 逻辑相邻的页，物理上不一定相邻
  * 典型页面尺寸： 4K或4M
  * 逻辑地址： 页号+页内地址
  * 页表：
    * 页表项：记录逻辑地址和物理地址的映射关系
    * 每个进程一个页表，一般放在内存
  * 空闲内存管理：bitmap
  * 地址转换：硬件支持：
    * 逻辑地址，CPU自动划分为页号和页内地址，用页号查页表得到页框号，再与页内偏移拼接成物理地址
  * 内碎片：页框内浪费空间
* 段式存储方案：
  * 按程序逻辑划分若干程序段，每个段一个段名
  * 内存空间被动态划分为长度不同的区域，称为物理段
  * 以段为单位进行划分，每段占连续空间，段之间可以不相邻
  * 逻辑地址 = 段号+段内地址 ， 无法自动划分
  * 段表： 记录每段长度和段起始地址，存放在内存
  * 物理内存管理：空闲区表
  * 地址转换：硬件支持：
    * 逻辑地址，用段号查段表，得到起始地址，与段内偏移地址计算出地址
* 段页式存储方案：
  * 综合页式，段式优点
  * 先按段划分，每个段按页划分
  * 逻辑地址：段号+页号+页内地址
  * 内存划分：同页式存储方案
  * 内存分配：以页为单位分配
  * 段表： 记录每一段页表起始地址和长度
  * 页表：逻辑页号和页框的对应关系
  * 一个进程一个段表多个页表，一个段表一个页表
  * 空闲区同页式管理

#### 交换技术 swapping

内存不足时的解决方案，当大的地址空间装不进小的内存空间

内存”扩充“技术

* 内存紧缩技术（可变分区）
* 覆盖技术 overlaying：（早期操作系统）
  * 程序大小超过物理内存总和
  * 程序不同部分在内存中相互替代，把不会同时执行的程序段共享同一内存区域
  * 要求程序各模块有明确的调用结构
  * 程序员声明覆盖结构，操作系统完成自动覆盖
  * 缺点：用户不透明，增加用户负担
* 交换技术 swapping：
  * 系统把内存中某些进程暂时移到外存，把外存某些进程换入内存
  * 问题：
    * 进程哪些内容要交换：运行中创建或修改的内容：栈和堆
    * 磁盘什么位置保存：交换区swap space：一块特殊的区域，包含连续的磁道，操作系统通过底层的磁盘读写操作对其高效访问
    * 交换时机：只要不用就换出； 内存空间不足或即将不足时
    * 如何选择被换出的进程：不应换出处于等待IO状态的进程
    * 如何处理进程空间增长：预留空间给数据段、栈增长
* 虚拟存储技术 virtual memory


### 存储模型（2） 虚拟存储

重点：

* 虚拟存储技术
* 虚拟页式存储方案的实现：
  * 多级页表、翻转页表、页表项、地址转换、MMU、快表TLB、页错误、缺页异常处理
* 软件策略：
  * 驻留集、置换范围、清除策略
  * 置换算法：OPT、FIFO、第二次机会、时钟算法、LRU、老化、工作集
* 虚存相关的软件技术：内存映射文件、写时复制

教材：

* 第三章：3.3、 3.4、 3.5.1、 3.5.7、 3.5.8、 3.6.1

#### 虚拟存储技术

定义： 进程运行时，一部分装入内存，另一部分暂留在磁盘，当要执行的指令或访问的数据不在内存时，由操作系统自动完成从磁盘调入内存的工作

虚拟地址空间：分配给进程的虚拟内存

虚拟地址：虚拟内存中指令或数据的位置

虚存是对内存的抽象，构建在存储体系之上，由操作系统协调各存储器的使用

大小限制：寻址空间和磁盘大小

地址保护：（硬件）

* 确保每个进程都有独立的地址空间
* 确保进程访问合法的地址范围： 基地址寄存器+界限寄存器
* 确保进程的操作是合法的

虚拟页式paging：

* 虚拟存储技术+页式存储方案
* 基本思想：
  * 进程开始前装入一个或0个页面
  * 根据进程需要动态装入其他页面
  * 当内存空间满，又需要装入新的页面，则根据置换算法置换某个页面，以装入新的页面
* 方式：
  * 请求调页 demand paging
  * 预先调页 prepaging
* 用CPU时间和磁盘空间换内存空间

#### 页表和页表项的设计

页表由页表项组成：

* 页框号：内存块号、物理页面号
* 有效位：表示该页在内存还是在磁盘
* 访问位R：引用位，表示这个页被访问过
* 修改位M：表示该页在内存中是否被修改过
* 保护位：读 / 可读写

通常页表项是硬件设计的

页表在内存不应该连续存放，因此需要引入页表页的地址索引表：页目录 page directory

二级页表：

* 虚拟地址： 页目录偏移+页表偏移+页内偏移
* 可以表示4G的虚拟地址
* 从页目录地址寄存器得到页目录首地址，加上页目录偏移得到页表首地址，加上页表偏移得到在第i个页表的页框号，页框号+页内偏移得到物理地址
* ![虚存页表](http://ot1c7ttzm.bkt.clouddn.com/virtualpage.png)

反转页表（倒排页表）：

* 每个进程一张页表过于庞大
* 从物理地址空间出发，系统建立一张页表
* 页表项记录进程i的某虚拟地址（虚页号）与页框号的映射关系
* 解决从虚拟地址到物理地址的映射：虚拟地址页号部分映射到散列值，散列值指向一个反转页表

#### 地址转换过程和TLB引入

虚拟地址到物理地址映射： MMU 内存管理单元

快表 TLB translation look-aside buffers的引入：

* 原因：
  * 页表需要进行多次内存访问
  * CPU指令处理速度和内存指令访问速度差异大
* 程序访问的局部性原理
* CPU中引入的高速缓存（cache），随机存取型存储器组成
* 有特殊的接线逻辑，能按特定的匹配标志在一个存储周期内对所有的字同时进行比较
* 相联存储器 associative memory：特点：按内容并行查找
* 保存正在运行进程的页表的子集


页错误：page fault

* 地址转换过程中硬件产生的异常
* 具体原因：
  * 缺页异常：所访问的虚拟页面没调入物理内存
  * 违反权限：读/写、用户/内核
  * 错误的访问地址
* 处理缺页异常：
  * 地址映射过程中，硬件检查页表发现所要页面不在内存
  * 操作系统执行缺页异常处理程序：获得磁盘地址、启动磁盘、将该页调入内存：
    * 内存中有空闲页框，修改页表中相应页表项的有效位和页框号
    * 内存中没有空闲页框，置换某一页，若该页修改过，还需要写回磁盘

#### 软件相关策略

驻留集：

* 操作系统给每个进程分配页框数目
* 策略：
  * 固定分配策略：
    * 进程创建时确定
    * 可以根据进程类型或程序员或系统管理员需要确定
  * 可变分配策略：
    * 根据缺页率评估进程局部性表现
    * 带来额外系统开销

页框锁定：

* 为什么要锁定页面：虚存技术使得进程运行时间不确定
* 给每一页框增加一个锁定位
* 不让操作系统将进程换出内存
* 如：操作系统核心代码，关键数据结构，IO缓冲区

置换问题：

* 置换范围：
  * 置换集合是局限于产生缺页中断的进程，还是所有进程的页框
  * 策略：
    * 局部置换：只在产生本次缺页的进程的驻留集中选择
    * 全局置换：将内存中所有未锁定的页框都作为置换的候选
* 置换策略：
  * 选择换出哪个页框
  * 目标：置换最近最不可能访问的页
  * 局部性原理：基于过去行为来预测将来行为
  * 但策略设置越复杂，实现时软硬件开销越大
  * 约束：不能置换锁定的页框

清除策略：

* 清除：从进程驻留集中集中回收页框（进程运行过程中回收）
* 需要在系统中保持一定数目空闲页框，使得系统在最佳状态工作
* 分页守护进程 paging daemon：
  * 大部分时间睡眠，定期唤醒检查内存状态
  * 若空闲页框数过少，该进程通过页面置换算法换出内存
  * 若页面被修改过，则写回磁盘，以保证所有空闲页框是干净的
* 页缓冲技术：
  * 不丢弃置换出的页，放入两个表之一：空闲链表和修改链表
  * 修改链表定期写回磁盘
  * 被置换的页仍在内存，一旦进程又要访问，则可以迅速将它加入进程的驻留集合

#### 置换算法 replacement

颠簸 thrashing：页面在内存和磁盘间调度的事件多于实际运行的时间

影响缺页次数的因素：

* 置换算法
* 页面大小：
  * 内部碎片
  * 页表长度
  * 辅存的物理特性
* 程序编制问题
* 分配给进程的页框数目

最佳页面置换算法 OPT：

* 置换以后不再需要或最远的将来才会用到的页面
* 无法实现
* 作用：作为一种标准来衡量其他算法性能

先进先出 FIFO：

* 选择在内存中驻留时间最长的页并置换
* 实现：页面链表法

第二次机会算法 SCR second chance：

* 按先进先出选择页面，检查其访问位R，若为0，则置换，若为1，则给第二次机会并把R置位0

时钟算法 CLOCK：

* SCR的改进，把链表改成环，用指针指向当前要置换的页

最近未使用算法 NRU：

* 最近未使用的一页
* 实现：根据页表项的两位：访问位R，修改位M（若硬件没有这两位，则用软件模拟）
* R位定期清零
* 优先级：
  * 1 最低：R=0，M=0，无使用，未修改
  * 2： R=0，M=1
  * 3： R=1，M=0
  * 4： R=1，M=1
* 时钟算法实现：
  * 环状链表，选中遇到第一个R=0，M=0,用于置换
  * 若没有，则扫描第一个 R=0，M=1，对每个跳过的页框，把R置为0
  * 若仍没有，重新扫描R=0，M=0
  * 若仍没有，则扫描 R=0，M=1

最近最少使用 LRU：

* 置换未使用时间最长的一页
* 性能最接近 OPT 最佳算法，使用最多
* 实现： 开销大，需要维护时间戳或访问页的栈

最不经常使用 NFU：

* LRU的一种软件解决方案（自说）
* 选择访问次数最少的页面置换
* 实现：
  * 软件计数器，每一个页一个，初值为0
  * 每次事件中断，计数器加该页的R
  * 缺页中断时，选择计数器最小的置换

老化算法 AGING：

* 对NFU的改进（模拟LRU）：
* 计数器在加R前先右移一位（除以2），R加到计数器最左端

BELADY现象：

* 页框数目多，缺页次数反而多

工作集working set 算法：

* 程序局部性： 活跃页面：进程一段时间中集中访问的页面
* 为进程提供和活跃页面数相等的物理页面数，则可以减少中断次数
* 工作集：当前正在使用的页框集合， W(t, delta)=该进程在时刻 t 过去 delta 事件单位中访问的页面的集合
* 核心思想：找出一个不在工作集的页面并置换它
* 思路：
  * 每个页表项记录该页面最后一次被访问的时间
  * 设置时间T
  * 判断：根据一个页面访问时间在 当前时间-T 之前或之中决定其在工作集之内还是之外
* 实现：扫描所有页表项：
  * 若 R=1，则把其最后一次访问时间设置为当前时间，R清零
  * R=0，则检查访问时间是否在 当前时间-T 之前（不在工作集）
    * 若是，则置换
    * 若不是，则记录最后访问时间的最小值

![置换算法](http://ot1c7ttzm.bkt.clouddn.com/replacement.png)

#### 其他技术

内存映射文件：

* 进程通过系统调用 mmap 将文件或部分 映射到虚拟地址空间的一部分，访问该文件就像访问内存中的大数组，而不是对文件进行读写
* 不会实际读入页面，在访问页面时才会被读入内存
* 进程退出或显示解除文件映射时，修改写回磁盘

写时复制技术：

* 多个进程共享页面，页标志为写时复制
* 进程试图改变页面数据时，操作系统复制一个页面，对执行写操作的进程是私有的


### 文件系统（1）

重点：

* 文件系统相关概念：文件、文件分类、文件逻辑结构和物理结构
* 文件目录的实现：文件控制块FCB、目录项、目录文件
* 文件系统的实现：磁盘布局、内存树结构
* 磁盘空间的管理：存储介质、扇区、物理块block、簇cluster

教材：

* 第四章：4.1、 4.2、 4.3、 4.5.3

#### 文件与文件系统

文件 是 对磁盘的抽象

文件：一组带标识的、在逻辑上有完整意义的信息项的序列

信息项：构成文件内容的基本单位（单个字节或多个字节），各信息项之间有顺序关系

文件内容的意义：由文件建立者和使用者解释

文件系统：操作系统中统一管理信息资源的一种软件，管理文件的存储、检索、更新，提供共享和保护手段：

* 统一管理磁盘空间，实施磁盘空间分配和回收
* 实现文件按名存取（名字空间 -> 映射 -> 磁盘空间）
* 实现文件信息的共享
* 向用户提供方便使用和维护的接口
* 提高文件系统性能
* 提供与IO系统的统一接口

文件分类：（UNIX）：按文件性质和用途

* 普通文件
* 目录文件
* 特殊文件（设备文件）：设备作为文件处理，分为字符设备或块设备
* 管道文件
* 套接字

文件的逻辑结构：

* 由用户的访问方式决定
* 典型文件逻辑结构：
  * 流式文件：文件是有逻辑意义、无结构的一串字符的集合
  * 记录式文件：文件由若干记录组成，可以按记录读写查找等
* 文件存取：
  * 顺序存取（访问）
  * 随机存取（访问）：提供读写位置

#### 文件的存储介质

典型存储介质：磁盘、磁带、光盘、U盘

物理块：

* 信息存储、传输、分配的独立单位
* 存储设备划分为大小相等的物理块，统一编号

典型磁盘结构：

* 任何时刻只有一个磁头处于活动状态：输入输出数据流以位串形式出现
* 物理地址形式：磁头号、磁道号、扇区号

磁盘访问：

* 寻道：磁头移动到指定磁道
* 旋转延迟：等待指定扇区
* 数据传输：数据在磁盘和内存之间实际传输

磁盘空间管理：

* 数据结构：
  * 位图：用二进制位反应块的分配情况，0为已经分配，1为空闲
  * 空闲块表：所有空闲块记录在一张表
  * 空闲块链表：**成组链接法**
  * ![成组链接法](http://ot1c7ttzm.bkt.clouddn.com/grouplink.png)

#### 文件属性

文件控制块 file control block：为了管理文件而设置的数据结构，保存所需要等待有关信息

文件目录：

*  统一管理每个文件的元数据，以支持文件名到文件物理地址的转换
*  将所有文件的管理信息组织在一起

目录文件：文件目录以文件的形式存放在磁盘上

目录项：

* 构成文件目录的基本单元
* 目录项可以是FCB，目录是文件控制块的有序集合

#### 文件的物理结构

文件在存储介质的存放方式

结构：

* 连续（顺序）结构：
  * 文件的信息在若干连续的物理块中
  * 优点：
    * 简单
    * 支持顺序存取、随机存取
    * 需要的磁盘寻道次数和寻道时间最少
    * 可以同时读入多个块，检索一个块也容易
  * 缺点：
    * 文件不能动态增长
    * 不利于文件插入和删除
    * 会产生外部碎片：紧缩技术
* 链接结构：
  * 一个文件的信息存放在若干不连续物理块中，各块用指针相连，前一个物理块指向下一个物理块
  * 优点：
    * 提高磁盘空间利用率，不存在外部碎片问题
    * 利于文件插入、删除
    * 利于文件动态扩充
  * 缺点：
    * 存取速度慢，不利于随机存取
    * 可靠性问题，如指针出错
    * 更多寻道时间和寻道次数
    * 链接指针占用空间
  * 变形：文件分配表 FAT：记录每个物理块的下一块的索引
* 索引结构：
  * 信息存放在若干不连续的物理块中
  * 系统为每个文件建立一个索引表，块号放在索引表
  * 索引表就是磁盘块地址数组
  * FCB放索引表的起始地址
  * 优点：
    * 保持链接结构优点，又解决其缺点：
      * 能顺序和随机存取
      * 满足文件动态增长、插入删除要求
  * 缺点：
    * 寻道次数和寻道时间多
    * 索引表需要额外空间
  * 组织方式：
    * 当索引表很大，需要多个物理块存放时：
      * 链接方式：一个盘块存一个表
      * 多级索引
      * 综合索引：直接索引加间接索引：部分直接索引，指向一个物理块，一部分间接寻址，指向索引表
  * UNIX 三级索引结构（综合模式）：
    * 每个文件主索引表放FCB中，有15项，每项2字节
    * 前12个直接寻址
    * 第13项指向一级索引表
    * 第14项作为二级索引表
    * 第15项作为三级索引表
    * 最大总文件大小 = 12 + 256 + 256*256 + 256^3 个block

#### 文件系统的实现

需要考虑： 磁盘上 和 内存中 内容布局

磁盘分区 partition：把一个物理磁盘存储空间划分为几个相互独立部分

文件卷 volume：磁盘上的逻辑分区，由一个或多个物理块组成：

* 一个文件卷可以使一个盘或部分盘或跨盘 RAID
* 同一个文件卷使用同一份管理数据
* 文件卷上：文件系统信息、一组文件（用户文件+目录文件）、未分配空间
* 块 block 或 簇cluster：

格式化 format：在一个文件卷上建立文件系统，建立并初始化元数据

UNIX：

 * FCB = 目录项 + i节点
 * 目录项 = 文件名+i节点号
 * i节点 = 保存描述文件的相关信息




### 文件系统（2）

重点：

* 文件操作的实现流程
* 文件系统的可靠性、一致性、写入策略、安全性
* 提高文件系统性能
* FAT文件系统的实现

#### 文件操作的实现

创建文件：

* 建立系统和文件的联系，实质是建立文件的FCB
* 在目录中为新文件建立一个目录项，填写参数
* 分配必要的存储空间
* 流程：
  1. 检查参数合法性（命名规则、重名文件等）
  2. 申请空闲目录项，填写相关信息
  3. 为文件申请磁盘块

打开文件：

* 根据文件名在文件目录中检索，找到目录项或FCB
* 将目录项读入内存，建立相应的数据结构（文件描述符或文件句柄），为后续操作做好准备
* 流程：
  1. 给出路径名查目录，找到目录项或i节点号
  2. 根据文件号查系统打开文件表
     1. 是 则共享计数加1
     2. 否 将信息填入系统打开文件表，共享计数为1
  3. 根据打开方式、共享说明和用户身份检查访问合法性
  4. 在用户打开文件表获取一个空表项，填写参数，返回文件句柄
* 指针定位：
  * 每个进程打开的每个文件维护一个读写指针
  * 在用户打开文件表中

读文件：

1. 根据打开文件时的文件描述符，找到FCB，确定操作合法性
2. 把文件的逻辑块号转换成物理块号
3. 申请缓冲区
4. 启动磁盘IO操作，把磁盘块内容送到缓冲区，而后送到内存

#### 文件系统的管理

可靠性：

* 抵御和预防各种物理性破坏和人为性破坏的能力
* 坏块问题
* 备份：通过转储操作，形成文件或文件系统的多个副本

转储：

* 全量转储：定期拷贝所有文件
* 增量转储：只转储修改过的文件，两次备份之间的修改
* 物理转储：从磁盘第0块开始，将所有磁盘块按序输出到磁带
* 逻辑转储：从指定目录开始，递归转储给定日期后所有更改的文件或目录

文件系统一致性：

* 问题的产生：磁盘块 -> 内存 -> 写回磁盘块，若在写回之前系统崩溃，则文件系统不一致（FCB、目录文件已经更新）
* 解决方案：设计程序，当系统再次启动时检查磁盘块和目录系统
* 磁盘块的一致性检查：
  * 用两张表，每个表项对应一个磁盘块，第一张表记录每个块在文件中出现的次数，第二张表记录在空闲块表中出现的次数
  * 情况1： 使用块和空闲块相反：正常
  * 情况2： 使用块和空闲块均为0：把空闲块置1
  * 情况3： 使用块和空闲块均为1：空闲块置0
  * 情况4： 使用块为2，空闲为0： 在空闲中寻找一个把多出的文件写入

写入策略：

* write-through：直写：内存中修改立刻返回磁盘：FAT
* lazy-write：延迟写：利用回写write back缓存的方法增加速度
* transaction log：可恢复写：利用事务日志实现文件系统写入 ： NTFS，EXT3

访问控制：

1. 主动控制：访问控制表：
   * 每个文件一张表
   * 记录用户id和访问权限
   * 用户可以是一组用户
   * 文件可以是一组文件
2. 能力表（权限表）
   * 每个用户一个
   * 记录文件名及访问权限
   * 用户可以是一组用户
   * 文件可以是一组文件

UNIX文件访问控制：

* 采用文件二级存取控制
* 第一级：对访问者的识别：
  * 对用户分类：
    * 文件主
    * 文件主的同组用户
    * 其他用户
* 第二级：对操作权限的识别：
  * 对操作分类：
    * 读 r
    * 写 w
    * 执行 x
    * 不能执行任何操作 -

#### 文件系统的性能

设计文件系统应该尽可能减少磁盘访问次数

方法：

* 目录项FCB分解、当前目录、磁盘碎片整理
* 块高速缓存 block cache：
  * 在内存中为磁盘块设置一个缓冲区，保存磁盘某些块的副本
  * 检查所有读请求，看是否在块高速缓存中
    * 若在，则直接读
    * 若不再，先将块拷入块高速缓存，再拷入所需地方
  * 组织：用hash
  * 置换：LRU
  * 写入策略（文件系统一致性）：定期写回磁盘
* 合理分配磁盘空间：
  * 分配磁盘块时，有可能顺序存取的块放在一起
  * 尽可能分配在同一柱面上，从而减少磁盘臂移动次数和距离
* 磁盘调度：
  * 有多个访盘请求时，采用一定策略调整顺序
  * 降低平均磁盘服务时间
  * 调度算法：
    * 先来先服务 FCFS
    * 最短寻道时间优先：优先选择离当前磁头最近的访问请求
      * 优点：改善平均服务请求
      * 缺点：饥饿现象
    * 扫描算法 SCAN （电梯算法）：按一个方向移动，若该方向没有请求，则改变方向
    * 单向扫描算法 C-SCAN：SCAN的改进：总从0号柱面向里扫描，到达最后一个柱面时，立即返回0号，返回时不服务，返回后再次扫描
    * N-step-SCAN策略：磁盘请求划分为长度为N的子队列，每一次用SCAN处理一个子队列
    * FSCAN策略：使用两个子队列，开始时请求在一个队列，扫描时请求加入另一个队列
    * 旋转调度：根据延迟时间决定执行次序的调度
* 信息的优化分布：
  * 记录在磁盘的排列方式
* 记录的成组与分解：
  * 若干逻辑记录合成一组存放
  * 成组操作必须用内存缓冲区，缓存区长度 = 记录长度 * 块因子
  * 目的：提高空间利用率和工作效率
* RAID 独立磁盘冗余阵列 技术：
  * 多块磁盘按一定要求构成一个独立存储设备
  * 目标：提高可靠性和性能
  * 组织：
    * 多个磁盘组织，作为一个逻辑卷
    * 数据分成多个数据块，并行写入、读出多个磁盘
    * 通过镜像或校验，提供容错能力（冗余）
  * 分类：
    * RAID 0-条带化，数据分布在所有磁盘上，无冗余，性能最佳
    * RAID 1 - 镜像：利用率 50%，所有数据同时保存在两块盘相同位置，安全性最好
    * RAID 4 -交错块奇偶校验：带奇偶校验，以数据块为单位 

Windows的文件访问方式：

* 不使用文件缓存
* 使用文件缓存：
  * Windows的cache manager实现对缓存的控制：
    * 读取数据时预取
    * 在cache满时，根据LRU清除缓存内容
    * 定期更新磁盘内容使其与cache一致
  * write-back机制：只更改cache内容，由cache manager定期写回
* 异步模式：
  * 不等待磁盘操作的完成
  * 使CPU和IO并发工作


### IO系统

重点：

* IO系统的概念：
  * IO设备的特点及分类
  * IO管理的任务
* IO管理的解决方案
  * IO硬件组成
  * IO控制方式
  * IO软件层次及功能
* IO相关技术
* IO性能提高的解决方案

教材：第五章：5.1、 5.2、 5.4

#### IO管理概述

IO设备管理：

* 逻辑IO：统一的操作，与具体设备无关
* 设备驱动程序
* 中断服务程序

![IO](http://ot1c7ttzm.bkt.clouddn.com/IO.png)

IO的特点：

* IO性能经常成为系统性能的瓶颈
* 操作系统庞大复杂的原因之一：IO资源多而杂，并发
  * 速度差异大
  * 应用
  * 控制接口的复杂性
  * 传送单位
  * 数据表示
  * 错误条件
* 与其他功能密切相关，尤其是文件系统

设备分类：

* 按数据组织分：
  * 块设备：
    * 以数据块为单位
    * 传输速度块，可寻址
  * 字符设备：
    * 以字符为单位
    * 速率低、不可寻址
* 从资源分配角度：
  * 独占设备：一段时间只能有一个进程使用，一般低速，如打印机
  * 共享设备：一段时间可有多个进程共同使用，以交叉方式使用
  * 虚设备：
    * 在一类设备上模拟另一类，常用 共享模拟独占、高速模拟低速
    * 实例：SPOOLing技术，用硬盘模拟输入输出

目标：

* 按用户请求，控制设备的各种操作，完成设备和内存的数据交换
  * 设备的分配和回收
    * 记录设备的状态
    * 根据用户请求和设备类型，采用一定分配算法，选择设备到内存的数据通路
  * 执行设备驱动程序
  * 设备中断处理
  * 缓冲区管理：管理IO缓冲区
* 建立方便统一的独立于设备的接口：通用性
  * 方便性：用户编程时不考虑设备的物理特性
  * 统一性：用户程序使用的是逻辑设备，以屏蔽硬件细节
* 利用各种技术提高CPU与设备、设备之间的并行工作能力，充分利用资源
  * 并行性
  * 均衡性
* ​

#### IO设备组成

一般由机械和电子部分组成：

* 机械部分是设备本身（物理装置）
* 电子部分又称设备控制器（适配器）
  * 地址译码
  * 接受计算机发来或向计算机发送数据和状态信号
  * 把计算机数字信号转换成机械能识别的模拟信号，或反过来
  * 设备内部硬件缓冲或数据加工等提升性能

机械部分：设备接口——控制器：

* 操作系统将命令写入控制器的接口寄存器，并从中读取状态信息或结果信息
* 控制器接受命令后独立于CPU执行，命令完成后产生中断，操作系统通过读控制寄存器的信息获取操作结果和状态
* 控制器和设备的接口通常是低级借口
* 控制器的任务：串行位流转换成字节块，并进行必要的错误修正

IO端口地址：

* 每个寄存器都有的唯一的地址
* 所有端口地址形成IO端口空间
* IO指令形式和IO地址关联：
  * 内存映像编址（内存映像IO模式）：内存一部分用作IO端口
    * 把IO端口看作一个存储单元
    * 优点：
      * 凡是可对内存的操作均可对IO操作
      * 不需要专门IO指令
      * IO端口空间大
      * 不需要专门机制阻止用户操作IO
    * 缺点：
      * 占用内存空间
      * 不能对控制寄存器进行高速缓存
  * IO独立编址（IO专用指令）：IO空间独立于内存
    * 使用专门的IO指令对端口操作
    * 优点：
      * 外设不占内存
      * 编程时可以区分对内存还是对IO
    * 缺点：IO操作指令类型少，操作不灵活

IO控制方式：

1. 可编程IO（轮询、查询）
   * CPU不断询问IO模块
   * 设置控制寄存器后不断查询状态寄存器，完成后把数据寄存器中数据读取
2. 中断驱动IO
   * IO结束后，由设备控制器主动通知设备驱动程序
3. DMA
   * 直接内存存取

#### IO软件组成

设计思想：

* IO软件组织成多层次
* 每层执行所需要功能的子集，依赖于低一层实现的功能
* 低层考虑硬件特性，向高层提供接口
* 高层不考虑硬件细节，提供良好接口

软件层次：

* 用户级IO
* 与设备无关的OS软件：
  * 驱动程序统一接口
  * 缓存
  * 错误报告
  * 分配与释放设备
  * 提供与设备无关的尺寸大小
* 设备驱动程序
* 中断处理程序

设备无关性：用户程序可以访问任意IO设备，无需事先指定设备

* 好处：易实现IO重定向，设备分配灵活

#### IO相关技术

缓冲技术：

* 凡是数据到达和离去速度不匹配的地方均可用缓冲技术
* 实现：
  * 硬缓冲：由硬件寄存器实现
  * 软缓存：内存中开辟空间作缓冲区
* 缓冲区管理：
  * 单缓冲
  * 双缓冲
  * 缓冲池（多缓存）：统一管理多个缓冲区，缓冲区循环使用
* UNIX缓冲技术：
  * 结合提前读和延迟写技术
  * 充分利用从磁盘读入，已传入用户区但仍在缓冲区的数据
  * 缓冲区组成：缓冲控制块+数据区
  * 空闲缓冲区对联 av链
  * 设备缓冲队列 b链：链接所有分配给设备使用的缓冲区，按散列方式组织

#### IO设备管理

独占设备的分配：

* 静态分配：
  * 运行前完成设备分配，结束时收回设备
  * 缺点：利用率低
* 动态分配：
  * 运行过程中，用户提出设备要求时进行分配，一旦停止使用立刻收回
  * 优点：效率高
  * 缺点：可能死锁

分时式共享设备：

* 以一次IO为单位分时使用设备，不同IO请求排队使用

设备驱动程序：

* 每个设备驱动程序管理一类设备
* 接收来自与设备无关的上层软件抽象请求，并执行请求
* 每个控制器有一个或多个设备寄存器用于存命令和参数，设备驱动程序负责释放命令并监督执行
* 与外界的接口：
  * 与操作系统的接口
  * 与系统引导的接口
  * 与设备的接口
* 接口函数
* IO进程：专门处理系统IO请求与IO中断

#### IO性能问题

核心：

* 使CPU利用率尽可能不被IO降低
* 使CPU尽可能摆脱IO

解决方案：

* 减少或缓解速度差距：缓冲技术
* 使CPU不等待IO：异步IO：用其他操作填充IO操作间等待的CPU时间
* 使CPU摆脱IO：DMA、通道


### 死锁

重点：

* 死锁的基本概念
  * 死锁的四个必要条件
  * 死锁和活锁、饥饿的区别
* 死锁的解决方案：
  * 死锁预防：资源的有序分配法
  * 死锁避免：银行家算法、安全/不安全状态
  * 死锁检测与解除
* 资源分配图和在解决死锁问题的应用
* 哲学家就餐问题



#### 基本概念

死锁：

 * 一组进程中每个进程都无限等待被该组另一进程占用的资源
 * 参与死锁的所有进程都在等待资源
 * 参与死锁的进程是当前系统中所有进程的子集

死锁的原因：

 * 资源数目有限、锁和信号量错误使用
 * 资源的使用方式： 申请 -- 分配 -- 使用 -- 释放
 * 资源分类：
    * 可重用资源：可被多个资源多次使用
       * 可抢占资源：CPU
       * 不可抢占资源：打印机
   * 可消耗资源：只使用一次、可创建和销毁的资源：如信号、中断、消息

活锁和饥饿：

* 活锁：得不到资源，但能够运行，既无进展也无阻塞
* 饥饿：资源分配策略决定

死锁的产生条件：

* 互斥使用（资源独占）：一个资源一次一个进程使用
* 占有且等待：在申请新资源的同时保持对原资源的占有
* 不可抢占、不可剥夺：资源只能由占有者自愿释放
* 循环等待

#### 资源分配图

用有向图描述系统资源和进程的状态

结点V：分为P 进程 ， R 资源

有向边E：有向边的集合，资源 R 指向 进程 P （资源分配）或 进程P 指向资源R（申请资源）

死锁定理：

* 资源分配图中没有环路，则没有死锁
* 图中存在环路，系统可能有死锁
* 若每个资源类只有一个资源实例，则 环路存在  <=> 死锁存在

#### 死锁预防

解决死锁的方法：

* 鸵鸟算法：不考虑死锁问题
* 不让死锁发生
  * 死锁预防：静态策略：设计合适的资源分配算法
  * 死锁避免：动态策略：以不让死锁发生为目标，跟踪和评估资源分配过程，根据评估结果决策是否分配
* 死锁检测与解除

死锁预防：

* 防止产生死锁的四个必要条件之一
* 破坏 互斥使用、资源独占 条件：
  * 资源转换技术：把独占资源变为共享资源
* 破坏 占有且等待 条件：
  * 方案1：每个进程运行前必须一次性申请所有资源，仅当进程需要的资源都可满足才一次性分配
    * 资源利用率低，饥饿现象
  * 方案2：申请新资源得不到满足而变为等待状态前，必须释放已经占有的所有资源
* 破坏 不可抢占 条件：
  * 申请的资源被其他进程占用时，可通过操作系统抢占资源（进程优先级不同）
    * 局限性：适用于状态易于保存和恢复的资源
* 破坏 循环等待 条件：
  * 资源有序分配法：进程申请资源时必须按资源编号的递增次序进行，否则操作系统不予分配

死锁避免：

* 对进程发出的资源申请进行动态检查，根据分配后是否会发送死锁或是否可能导致死锁决定是否分配资源

* 安全状态：系统中存在一个由所有进程构成的安全序列，对每个进程 Pi 以后所需要资源量不超过 （系统当前剩余资源+所有进程Pj( j<i )当前所占有的资源）

* 安全状态一定不死锁，不安全状态一定导致死锁（哪怕当前未死锁）

* 银行家算法 banker's algorithm：仿照银行发放贷款采取的控制方式

  * 应用条件：

    * 固定数目进程 共享 固定数目资源
    * 每个进程预先指定所需要的最大资源数
    * 进程不能申请大于系统可用资源总数的资源
    * 进程等待资源的时间有限
    * 系统满足进程的最大需求后，进程应在有限时间内尽快使用并归还

  * 变量：

    * n：进程数目
    * m：资源类数目
    * available   【1.m】系统每类资源剩余数目
    * max  【1.n 1.m】每个进程对每类资源要求的最大数目
    * allocation 【1.n 1.m】每个进程已经分配的每类资源数目
    * need 【1.n 1.m】每个进程还需要的每类资源的数目
    * request 【1.n 1.m】 这次每个进程申请的每类资源数目

  * 步骤：

    1. 若 request[i] <= need[i] 继续，否则报错

    2. 若 request[i] <= available 继续，否则等待

    3. 假设系统分配了资源：

        available -= request[i]

        allocation[i] += request[i] 

        need[i] -= request[i]

    4. 若系统新状态安全，则分配完成，若不安全，则恢复分配

  * 安全性检查：

    1. work = available，finish=false
    2. 检查每个i 有 finish[i]==false && need[i]<=work
    3. 而后 work += allocation[i];  finish[i]=true, 转2
    4. 若对所有i都有 finish[i]==true 则系统安全

#### 死锁检测与解除

死锁检测：

* 允许死锁发生，但操作系统不断监视系统，判断死锁是否发生
* 一旦发生死锁则解除死锁并以最小代价恢复系统运行
* 检测时机：
  * 当进程由于资源请求不满足而等待时
  * 定时检测
  * 系统资源利用率下降时

死锁解除：

1. 撤销所有死锁进程
2. 进程回退roll back ，再启动
3. 按某原则逐一撤销死锁进程
4. 按某种原则逐一抢占资源
